{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_saver.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcyG45yzh2Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import math\n",
        "import pickle # just cuz\n",
        "import io\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import Perceptron \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# import hyperparameter optimization tools\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AWam0FHhHtS",
        "colab_type": "code",
        "outputId": "cb96c99f-e002-43ba-fde9-6ad46e52cef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ7mRwQ-jU_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(name = 'train'):\n",
        "    filepath = \"/content/gdrive/My Drive/data/\"+name+\".txt\"\n",
        "\n",
        "    data = io.open(filepath, \"r\", encoding='latin-1')\n",
        "    X = data.read().split(\"\\n\")\n",
        "    if X[-1] == '': X.pop()\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgxWrCy1l79i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_variations = ['easy', 'big', 'massive', 'hard', 'exam']\n",
        "def initialize_datasets():\n",
        "    train = get_data('train')\n",
        "    valid = get_data('validate')\n",
        "    test = []\n",
        "    for variation in test_variations:\n",
        "        test.append(get_data('test_' + variation))\n",
        "    return train, valid, test\n",
        "\n",
        "train, valid, test = initialize_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBbi9ecku_Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def find_replace(string, dictionary):\n",
        "    for char in string:\n",
        "        if char in dictionary.keys():\n",
        "            string = string.replace(char, dictionary[char])\n",
        "    return string\n",
        "\n",
        "def parse_vars(data_line):\n",
        "    count = 0\n",
        "    var_dict = {}\n",
        "    alphabet = []\n",
        "    for letter in range(97,123):\n",
        "        alphabet.append(chr(letter))\n",
        "    for char in data_line:\n",
        "        if char.isalpha():\n",
        "            if char not in var_dict.keys():\n",
        "                var_dict[char] = alphabet[0]\n",
        "                #print(var_dict)\n",
        "                alphabet.pop(0)\n",
        "                count+=1 \n",
        "    parsed_string = find_replace(data_line,var_dict)\n",
        "    outputs = parsed_string.split(\",\")\n",
        "    \n",
        "    a = outputs[0]\n",
        "    b = outputs[1]\n",
        "    y = outputs[2]\n",
        "    return a, b, y, count\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB3im3UFn0Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_vocab(n = 24):\n",
        "    vocab = {'~': 0, '&': 1, '|': 2, '>': 3}\n",
        "    index = 0\n",
        "    while index < n:\n",
        "        vocab[str(chr(97 + index))] = index + 4\n",
        "        index += 1\n",
        "    return vocab\n",
        "\n",
        "# line, count = parse_vars(str)\n",
        "def vectorize(dataset, vocab_length = 24, ngram = 1):\n",
        "    vocab = generate_vocab(vocab_length)\n",
        "    X = []\n",
        "    Y = [] \n",
        "    for line in dataset:  \n",
        "        a, b, y, count = parse_vars(line)  \n",
        "        X.append(a+b)\n",
        "        Y.append(y) \n",
        "        \n",
        "    vectorizer = CountVectorizer(analyzer = 'char', ngram_range = (1,ngram), vocabulary = vocab) \n",
        "    vectorizer.fit(X)\n",
        "    X = vectorizer.fit_transform(X) \n",
        "    return X, np.array(Y)\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ujNYzfYuPpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train = vectorize(train)\n",
        "X_valid, Y_valid = vectorize(valid)\n",
        "#print(X_train.shape)\n",
        "X_test, Y_test = [], [] \n",
        "for data in test:  \n",
        "    X, Y = vectorize(data)\n",
        "    X_test.append(X)\n",
        "    Y_test.append(Y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHObKis-d7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize testfold\n",
        "test_fold = np.zeros(X_train.shape[0] + X_valid.shape[0])\n",
        "for i in range(X_train.shape[0]): test_fold[X_train.shape[0]]     = -1\n",
        "for i in range(X_valid.shape[0]): test_fold[X_train.shape[0] + i] = 1\n",
        "ps = PredefinedSplit(test_fold)\n",
        "\n",
        "# Prepare input/output matrices  \n",
        "\n",
        "X_train_coo = coo_matrix(X_train)\n",
        "X_valid_coo = coo_matrix(X_valid)\n",
        "X = sp.sparse.csr_matrix(sp.sparse.vstack([X_train_coo, X_valid_coo]))  \n",
        "Y = np.concatenate((np.array(Y_train),np.array(Y_valid)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppfqj4Jn9tlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_and_print(model, X, Y, X_train, X_valid, X_test, Y_train, Y_valid, Y_test):\n",
        "    \n",
        "    model.fit(X, Y)\n",
        "    accuracy_train = accuracy_score(Y_train, model.predict(X_train))\n",
        "    accuracy_valid = accuracy_score(Y_valid, model.predict(X_valid))\n",
        "    test_accuracy = [] \n",
        "    for i in range(len(X_test)):\n",
        "        test_accuracy.append(accuracy_score(Y_test[i], model.predict(X_test[i])))\n",
        "    \n",
        "    print(\"Train Accuracy: \", accuracy_train)\n",
        "    print(\"Valid Accuracy: \", accuracy_valid) \n",
        "    for i in range(len(X_test)):\n",
        "        print(\"Test\", test_variations[i],\"Accuracy:\", test_accuracy[i])\n",
        "    print('Hyperparams:', model.best_params_)    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNp35F7TnCLI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_D87CWv92V5",
        "colab_type": "code",
        "outputId": "6c49d3a1-869c-4966-81ce-f4f1c5b38cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "SLP_parameters = [{     'penalty' : ['l2', 'l1', 'elasticnet', None], \n",
        "\t\t\t\t\t\t'random_state': [2,3,4,11],\n",
        "                        'alpha': [0.0001, 0.00001, 0.001, 0.002, 0.004, 0.007, 0.01, 0.025, 0.05]\n",
        "\t\t\t\t\t\t}]\n",
        "SLP = GridSearchCV(Perceptron(), SLP_parameters, cv=ps) \n",
        "fit_and_print(SLP, X, Y, X_train, X_valid, X_test, Y_train, Y_valid, Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy:  0.5030437742801074\n",
            "Valid Accuracy:  0.4848\n",
            "Test easy Accuracy: 0.4924\n",
            "Test big Accuracy: 0.5005896226415094\n",
            "Test massive Accuracy: 0.5\n",
            "Test hard Accuracy: 0.5014\n",
            "Test exam Accuracy: 0.53\n",
            "Hyperparams: {'alpha': 0.007, 'penalty': 'l2', 'random_state': 3}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wbMMtxtDoYW",
        "colab_type": "code",
        "outputId": "f9b73015-1ea9-46ad-8821-960f0ba7855d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "MLP_parameters = [{     'alpha': [1e-4, 1e-5],#, 1e-5, 1e-3\n",
        "                        'activation': ['identity', 'logistic', 'tanh', 'relu'],#\n",
        "\t\t\t\t\t\t'hidden_layer_sizes': [(25,5)],#(155,3) #good (149,2) (20,4)\n",
        "                        'random_state':[9]\n",
        "\t\t\t\t\t\t}]\n",
        "\n",
        "MLP = GridSearchCV(MLPClassifier(), MLP_parameters, cv=ps)\n",
        "fit_and_print(MLP, X, Y, X_train, X_valid, X_test, Y_train, Y_valid, Y_test)\n",
        "#8:31PM 12.5.2018 C.E."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy:  0.5788878208979135\n",
            "Valid Accuracy:  0.5544\n",
            "Test easy Accuracy: 0.5428\n",
            "Test big Accuracy: 0.4988207547169811\n",
            "Test massive Accuracy: 0.49955156950672647\n",
            "Test hard Accuracy: 0.509\n",
            "Test exam Accuracy: 0.56\n",
            "Hyperparams: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (25, 5), 'random_state': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKCiUmBwl0vG",
        "colab_type": "code",
        "outputId": "500446e5-197a-4b34-c9d7-d71af060f610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Random Classifier\n",
        "print('\\nDummy')\n",
        "DUM = DummyClassifier(strategy='uniform')\n",
        "DUM.fit(X, Y) #\n",
        "for i in range(len(X_test)): \n",
        "    print(\"Test\", test_variations[i],\"Accuracy:\", accuracy_score(Y_test[i], DUM.predict(X_test[i])))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dummy\n",
            "Test easy Accuracy: 0.4998\n",
            "Test big Accuracy: 0.49233490566037735\n",
            "Test massive Accuracy: 0.4923766816143498\n",
            "Test hard Accuracy: 0.498\n",
            "Test exam Accuracy: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MssoaSZIl9IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naive Bayes\n",
        "print('\\nNaive Bayes')\n",
        "smoothing = [0.0001, 0.00001, 0.001,0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015, 0.017, 0.019, 0.02,0.021, 0.025, 0.03, 0.035, 0.037, 0.039, 0.04, 0.041, 0.042, 0.044, 0.048, 0.05,0.1, 0.2, 0.5, 0.8, 1]\n",
        "#NB_parameters = [{'alpha': smoothing, 'binarize': [0.5]}]\n",
        "NB_parameters = [{'alpha': smoothing}]\n",
        "#MultinomialNB\n",
        "#NB = GridSearchCV(BernoulliNB(), NB_parameters, cv=ps)\n",
        "NB = GridSearchCV(MultinomialNB(), NB_parameters, cv=ps)\n",
        "fit_and_print(NB, X, Y, X_train, X_valid, X_test, Y_train, Y_valid, Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLHJmbComAeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Linear SVM\n",
        "print('\\nLinear SVM')\n",
        "SVM_parameters = [{ 'penalty' : ['l2'],\n",
        "                    'loss' : ['squared_hinge'],\n",
        "                    'dual' : [False],\n",
        "                    'tol': [0.00005, 0.0001, 0.001],\n",
        "                    'C': [0.0001, 0.00001, 0.001, 0.002, 0.004, 0.007, 0.01, 0.025, 0.05] }]\n",
        "SVM = GridSearchCV(LinearSVC(), SVM_parameters, cv=ps)\n",
        "fit_and_print(SVM, X, Y, X_train, X_valid, X_test, Y_train, Y_valid, Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KltVl2RsmCY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DecisionTreeClassifier  \n",
        "print('\\nDecision Tree Classifier')\n",
        "DT_parameters = [{  'criterion': ['gini','entropy'],#'gini',\n",
        "                    'splitter' : ['random', 'best'],#\n",
        "                    'min_samples_split': [4],\n",
        "                    'min_samples_leaf': [2],\n",
        "                    'min_weight_fraction_leaf': [0.04, 0.4,0.2],\n",
        "                    #'max_features':['auto','sqrt','log2',None],\n",
        "                    'random_state':[None, 8],\n",
        "                    'max_leaf_nodes':[3,4,5,None],\n",
        "                    'min_impurity_decrease':[0.0,0.01,0.1],\n",
        "                    #'class_weight':['balanced',None]\n",
        "                    }]\n",
        "DT = GridSearchCV(DecisionTreeClassifier(), DT_parameters, cv=ps)\n",
        "fit_and_print(DT, X, Y, X_train, X_valid, X_test, Y_train, Y_valid, Y_test)\n",
        "#3:35"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}